{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bb86170e-2226-491a-8aec-e01925008746"
    }
   },
   "source": [
    "#### * Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbpresent": {
     "id": "8afd8752-1ca6-4fe1-b14d-b16615d0199b"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import IPython\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "#from include import helpers\n",
    "\n",
    "from tensorflow.keras import backend as keras_backend\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout,Flatten,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a7b58aa0-2b3c-4854-a099-31d117ba74e1"
    }
   },
   "source": [
    "#### * Load MFCC data\n",
    "\n",
    "Data is an NumPy float32 array of shape (8732, 40, 174), 8732 samples with 40 MFCC coefficients and 174 frames. Each feature was zero-centered and scaled between -1 and 1 during extraction.<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbpresent": {
     "id": "87d3ebd1-0d75-4ea4-8f12-9f891a72d3e2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,) (923, 40, 431) (923,)\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.abspath('C:\\\\Users\\\\LENOVO\\\\Desktop\\\\SE\\\\Project')\n",
    "# Define a labels array for future use\n",
    "# Pre-processed MFCC coefficients\n",
    "X = np.load(data_path+\"\\\\train_dataset\\\\X-mfcc.npy\")\n",
    "y = np.load(data_path+\"\\\\train_dataset\\\\y-mfcc.npy\")\n",
    "\n",
    "# Metadata\n",
    "metadata = pd.read_csv(data_path+\"\\\\train_dataset\\\\train_data.csv\",encoding='unicode_escape')\n",
    "labels = metadata['ebird_code'].unique()\n",
    "print(labels.shape,X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f8043a00-6bfa-41ca-807f-a49d7430b65a"
    }
   },
   "source": [
    "### 1. Data preparation: features + metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Train / Test split\n",
    "\n",
    "Note that we are using the same index order for both the MFCC arrays and the metadata to keep track of the origin of each feature.<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test split: 184 \t\t Train split: 739\n",
      "X test shape: (184, 40, 431) \t X train shape: (739, 40, 431)\n",
      "y test shape: (184,) \t\t y train shape: (739,)\n"
     ]
    }
   ],
   "source": [
    "indexes = []\n",
    "total = len(metadata)\n",
    "indexes = list(range(0, total))\n",
    "\n",
    "# Randomize indexes\n",
    "random.shuffle(indexes)\n",
    "\n",
    "# Divide the indexes into Train and Test\n",
    "test_split_pct = 20\n",
    "split_offset = math.floor(test_split_pct * total / 100)\n",
    "\n",
    "# Split the metadata\n",
    "test_split_idx = indexes[0:split_offset]\n",
    "train_split_idx = indexes[split_offset:total]\n",
    "\n",
    "\n",
    "# Split the features with the same indexes\n",
    "X_test = np.take(X, test_split_idx, axis=0)\n",
    "y_test = np.take(y, test_split_idx, axis=0)\n",
    "X_train = np.take(X, train_split_idx, axis=0)\n",
    "y_train = np.take(y, train_split_idx, axis=0)\n",
    "\n",
    "# Also split metadata\n",
    "test_meta = metadata.iloc[test_split_idx]\n",
    "train_meta = metadata.iloc[train_split_idx]\n",
    "\n",
    "# Print status\n",
    "print(\"Test split: {} \\t\\t Train split: {}\".format(len(test_meta), len(train_meta)))\n",
    "print(\"X test shape: {} \\t X train shape: {}\".format(X_test.shape, X_train.shape))\n",
    "print(\"y test shape: {} \\t\\t y train shape: {}\".format(y_test.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 One hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbpresent": {
     "id": "65b227e7-2fe5-4582-bd79-c9e9b1b85d4e"
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_test_encoded = to_categorical(le.fit_transform(y_test))\n",
    "y_train_encoded = to_categorical(le.fit_transform(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "720605ff-4689-47dc-b142-023ea206a50c"
    }
   },
   "source": [
    "#### 1.3 Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbpresent": {
     "id": "d742676a-5a23-4fc8-856a-ad5505238d45"
    }
   },
   "outputs": [],
   "source": [
    "# How data should be structured\n",
    "num_rows = 40\n",
    "num_columns = 431 \n",
    "num_channels = 1\n",
    "\n",
    "# Reshape to fit the network input (channel last)\n",
    "X_train = X_train.reshape(X_train.shape[0], num_rows, num_columns, num_channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "# Total number of labels to predict (equal to the network output nodes)\n",
    "num_labels = y_train_encoded.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "23ae43f0-1d59-44ab-818d-54faeecf4f1c"
    }
   },
   "source": [
    "#### 2.1 Model definition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "nbpresent": {
     "id": "845659a2-b4b4-4380-8d8f-51144a91ccab"
    }
   },
   "outputs": [],
   "source": [
    "# Create a secquential object\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# Conv 1\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),input_shape=(num_rows, num_columns, num_channels)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "# Softmax output\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "nbpresent": {
     "id": "b56bca3e-3fd0-4033-9d13-20db795d02f0"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 38, 429, 32)       320       \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 36, 427, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 12, 142, 64)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 12, 142, 64)       0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 10, 140, 64)       36928     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 3, 46, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 3, 46, 64)         0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 3, 46, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 8832)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                565312    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 12)                780       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 622,092\n",
      "Trainable params: 621,964\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=0.001)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy'], \n",
    "    optimizer=adam)\n",
    "# Display model architecture summary \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "94bf431f-27a8-4b01-b7aa-41a1947c9233"
    }
   },
   "source": [
    "#### 2.3 Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.7829 - accuracy: 0.1019\n",
      "Epoch 1: val_loss improved from inf to 2.48708, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 20s 3s/step - loss: 2.7829 - accuracy: 0.1019 - val_loss: 2.4871 - val_accuracy: 0.0806\n",
      "Epoch 2/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.3867 - accuracy: 0.1728\n",
      "Epoch 2: val_loss improved from 2.48708 to 2.48071, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 21s 3s/step - loss: 2.3867 - accuracy: 0.1728 - val_loss: 2.4807 - val_accuracy: 0.1290\n",
      "Epoch 3/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.2830 - accuracy: 0.2216\n",
      "Epoch 3: val_loss improved from 2.48071 to 2.47002, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 23s 4s/step - loss: 2.2830 - accuracy: 0.2216 - val_loss: 2.4700 - val_accuracy: 0.1774\n",
      "Epoch 4/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.1614 - accuracy: 0.2614\n",
      "Epoch 4: val_loss improved from 2.47002 to 2.46069, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 24s 4s/step - loss: 2.1614 - accuracy: 0.2614 - val_loss: 2.4607 - val_accuracy: 0.1613\n",
      "Epoch 5/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.0375 - accuracy: 0.3058\n",
      "Epoch 5: val_loss improved from 2.46069 to 2.44685, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 22s 4s/step - loss: 2.0375 - accuracy: 0.3058 - val_loss: 2.4469 - val_accuracy: 0.3871\n",
      "Epoch 6/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.9404 - accuracy: 0.3279\n",
      "Epoch 6: val_loss improved from 2.44685 to 2.42416, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 23s 4s/step - loss: 1.9404 - accuracy: 0.3279 - val_loss: 2.4242 - val_accuracy: 0.4194\n",
      "Epoch 7/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.8433 - accuracy: 0.3796\n",
      "Epoch 7: val_loss improved from 2.42416 to 2.41291, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 24s 4s/step - loss: 1.8433 - accuracy: 0.3796 - val_loss: 2.4129 - val_accuracy: 0.3226\n",
      "Epoch 8/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.7322 - accuracy: 0.3900\n",
      "Epoch 8: val_loss improved from 2.41291 to 2.40595, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 23s 4s/step - loss: 1.7322 - accuracy: 0.3900 - val_loss: 2.4060 - val_accuracy: 0.3387\n",
      "Epoch 9/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.6684 - accuracy: 0.4490\n",
      "Epoch 9: val_loss improved from 2.40595 to 2.38948, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 23s 4s/step - loss: 1.6684 - accuracy: 0.4490 - val_loss: 2.3895 - val_accuracy: 0.4032\n",
      "Epoch 10/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.5480 - accuracy: 0.4697\n",
      "Epoch 10: val_loss improved from 2.38948 to 2.38036, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 23s 4s/step - loss: 1.5480 - accuracy: 0.4697 - val_loss: 2.3804 - val_accuracy: 0.3871\n",
      "Epoch 11/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4619 - accuracy: 0.4978 \n",
      "Epoch 11: val_loss improved from 2.38036 to 2.36638, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 51s 9s/step - loss: 1.4619 - accuracy: 0.4978 - val_loss: 2.3664 - val_accuracy: 0.5000\n",
      "Epoch 12/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.3364 - accuracy: 0.5790\n",
      "Epoch 12: val_loss improved from 2.36638 to 2.33922, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 34s 5s/step - loss: 1.3364 - accuracy: 0.5790 - val_loss: 2.3392 - val_accuracy: 0.4839\n",
      "Epoch 13/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.2074 - accuracy: 0.5908\n",
      "Epoch 13: val_loss improved from 2.33922 to 2.30356, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 25s 4s/step - loss: 1.2074 - accuracy: 0.5908 - val_loss: 2.3036 - val_accuracy: 0.4677\n",
      "Epoch 14/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.1608 - accuracy: 0.6115\n",
      "Epoch 14: val_loss improved from 2.30356 to 2.29042, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 21s 4s/step - loss: 1.1608 - accuracy: 0.6115 - val_loss: 2.2904 - val_accuracy: 0.5323\n",
      "Epoch 15/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.0107 - accuracy: 0.6632\n",
      "Epoch 15: val_loss improved from 2.29042 to 2.28290, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 19s 3s/step - loss: 1.0107 - accuracy: 0.6632 - val_loss: 2.2829 - val_accuracy: 0.5323\n",
      "Epoch 16/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9425 - accuracy: 0.6736\n",
      "Epoch 16: val_loss improved from 2.28290 to 2.23074, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.9425 - accuracy: 0.6736 - val_loss: 2.2307 - val_accuracy: 0.5000\n",
      "Epoch 17/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.8324 - accuracy: 0.7179\n",
      "Epoch 17: val_loss improved from 2.23074 to 2.21423, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.8324 - accuracy: 0.7179 - val_loss: 2.2142 - val_accuracy: 0.5161\n",
      "Epoch 18/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.7223 - accuracy: 0.7607\n",
      "Epoch 18: val_loss improved from 2.21423 to 2.16035, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 21s 3s/step - loss: 0.7223 - accuracy: 0.7607 - val_loss: 2.1604 - val_accuracy: 0.5323\n",
      "Epoch 19/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6688 - accuracy: 0.7799\n",
      "Epoch 19: val_loss improved from 2.16035 to 2.12751, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.6688 - accuracy: 0.7799 - val_loss: 2.1275 - val_accuracy: 0.5645\n",
      "Epoch 20/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5394 - accuracy: 0.8316\n",
      "Epoch 20: val_loss improved from 2.12751 to 2.10181, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 21s 3s/step - loss: 0.5394 - accuracy: 0.8316 - val_loss: 2.1018 - val_accuracy: 0.5806\n",
      "Epoch 21/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5021 - accuracy: 0.8612\n",
      "Epoch 21: val_loss improved from 2.10181 to 2.00982, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 22s 4s/step - loss: 0.5021 - accuracy: 0.8612 - val_loss: 2.0098 - val_accuracy: 0.6129\n",
      "Epoch 22/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4303 - accuracy: 0.8656\n",
      "Epoch 22: val_loss did not improve from 2.00982\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.4303 - accuracy: 0.8656 - val_loss: 2.0223 - val_accuracy: 0.5161\n",
      "Epoch 23/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4174 - accuracy: 0.8597\n",
      "Epoch 23: val_loss improved from 2.00982 to 1.98845, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.4174 - accuracy: 0.8597 - val_loss: 1.9885 - val_accuracy: 0.5968\n",
      "Epoch 24/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3436 - accuracy: 0.9055 \n",
      "Epoch 24: val_loss improved from 1.98845 to 1.90529, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 56s 10s/step - loss: 0.3436 - accuracy: 0.9055 - val_loss: 1.9053 - val_accuracy: 0.5323\n",
      "Epoch 25/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2919 - accuracy: 0.9188\n",
      "Epoch 25: val_loss improved from 1.90529 to 1.85807, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 38s 6s/step - loss: 0.2919 - accuracy: 0.9188 - val_loss: 1.8581 - val_accuracy: 0.5968\n",
      "Epoch 26/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2549 - accuracy: 0.9306\n",
      "Epoch 26: val_loss improved from 1.85807 to 1.82703, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 22s 4s/step - loss: 0.2549 - accuracy: 0.9306 - val_loss: 1.8270 - val_accuracy: 0.5806\n",
      "Epoch 27/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2510 - accuracy: 0.9202\n",
      "Epoch 27: val_loss improved from 1.82703 to 1.79166, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 19s 3s/step - loss: 0.2510 - accuracy: 0.9202 - val_loss: 1.7917 - val_accuracy: 0.6452\n",
      "Epoch 28/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2051 - accuracy: 0.9439\n",
      "Epoch 28: val_loss improved from 1.79166 to 1.75548, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 18s 3s/step - loss: 0.2051 - accuracy: 0.9439 - val_loss: 1.7555 - val_accuracy: 0.6613\n",
      "Epoch 29/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2105 - accuracy: 0.9380\n",
      "Epoch 29: val_loss improved from 1.75548 to 1.71130, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 19s 3s/step - loss: 0.2105 - accuracy: 0.9380 - val_loss: 1.7113 - val_accuracy: 0.6129\n",
      "Epoch 30/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1684 - accuracy: 0.9498\n",
      "Epoch 30: val_loss improved from 1.71130 to 1.66314, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 19s 3s/step - loss: 0.1684 - accuracy: 0.9498 - val_loss: 1.6631 - val_accuracy: 0.6129\n",
      "Epoch 31/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.9453\n",
      "Epoch 31: val_loss improved from 1.66314 to 1.62929, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 19s 3s/step - loss: 0.1794 - accuracy: 0.9453 - val_loss: 1.6293 - val_accuracy: 0.6290\n",
      "Epoch 32/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.9527\n",
      "Epoch 32: val_loss improved from 1.62929 to 1.58086, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.1561 - accuracy: 0.9527 - val_loss: 1.5809 - val_accuracy: 0.6613\n",
      "Epoch 33/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 0.9557\n",
      "Epoch 33: val_loss did not improve from 1.58086\n",
      "6/6 [==============================] - 19s 3s/step - loss: 0.1580 - accuracy: 0.9557 - val_loss: 1.5871 - val_accuracy: 0.6129\n",
      "Epoch 34/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.9601\n",
      "Epoch 34: val_loss did not improve from 1.58086\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.1352 - accuracy: 0.9601 - val_loss: 1.6246 - val_accuracy: 0.7097\n",
      "Epoch 35/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.9778\n",
      "Epoch 35: val_loss did not improve from 1.58086\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0979 - accuracy: 0.9778 - val_loss: 1.5886 - val_accuracy: 0.7097\n",
      "Epoch 36/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9690\n",
      "Epoch 36: val_loss improved from 1.58086 to 1.50694, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 19s 3s/step - loss: 0.1238 - accuracy: 0.9690 - val_loss: 1.5069 - val_accuracy: 0.6935\n",
      "Epoch 37/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9808\n",
      "Epoch 37: val_loss improved from 1.50694 to 1.46827, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0903 - accuracy: 0.9808 - val_loss: 1.4683 - val_accuracy: 0.5968\n",
      "Epoch 38/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9764\n",
      "Epoch 38: val_loss improved from 1.46827 to 1.45477, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 21s 3s/step - loss: 0.0903 - accuracy: 0.9764 - val_loss: 1.4548 - val_accuracy: 0.6290\n",
      "Epoch 39/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9778\n",
      "Epoch 39: val_loss improved from 1.45477 to 1.40447, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0804 - accuracy: 0.9778 - val_loss: 1.4045 - val_accuracy: 0.6935\n",
      "Epoch 40/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9852\n",
      "Epoch 40: val_loss improved from 1.40447 to 1.37017, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0637 - accuracy: 0.9852 - val_loss: 1.3702 - val_accuracy: 0.6774\n",
      "Epoch 41/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9764\n",
      "Epoch 41: val_loss improved from 1.37017 to 1.31926, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0860 - accuracy: 0.9764 - val_loss: 1.3193 - val_accuracy: 0.6935\n",
      "Epoch 42/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9882\n",
      "Epoch 42: val_loss improved from 1.31926 to 1.26501, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0632 - accuracy: 0.9882 - val_loss: 1.2650 - val_accuracy: 0.6452\n",
      "Epoch 43/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9793\n",
      "Epoch 43: val_loss improved from 1.26501 to 1.26271, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0698 - accuracy: 0.9793 - val_loss: 1.2627 - val_accuracy: 0.6774\n",
      "Epoch 44/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 0.9749\n",
      "Epoch 44: val_loss did not improve from 1.26271\n",
      "6/6 [==============================] - 21s 3s/step - loss: 0.0845 - accuracy: 0.9749 - val_loss: 1.2806 - val_accuracy: 0.6935\n",
      "Epoch 45/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9808\n",
      "Epoch 45: val_loss did not improve from 1.26271\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0666 - accuracy: 0.9808 - val_loss: 1.3243 - val_accuracy: 0.6613\n",
      "Epoch 46/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9897\n",
      "Epoch 46: val_loss did not improve from 1.26271\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0485 - accuracy: 0.9897 - val_loss: 1.3434 - val_accuracy: 0.6452\n",
      "Epoch 47/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9838\n",
      "Epoch 47: val_loss improved from 1.26271 to 1.25811, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.0509 - accuracy: 0.9838 - val_loss: 1.2581 - val_accuracy: 0.6129\n",
      "Epoch 48/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9823\n",
      "Epoch 48: val_loss did not improve from 1.25811\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.0629 - accuracy: 0.9823 - val_loss: 1.2920 - val_accuracy: 0.6129\n",
      "Epoch 49/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9867\n",
      "Epoch 49: val_loss did not improve from 1.25811\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.0523 - accuracy: 0.9867 - val_loss: 1.3800 - val_accuracy: 0.6774\n",
      "Epoch 50/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9882\n",
      "Epoch 50: val_loss did not improve from 1.25811\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0522 - accuracy: 0.9882 - val_loss: 1.3804 - val_accuracy: 0.6774\n",
      "Epoch 51/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9970\n",
      "Epoch 51: val_loss improved from 1.25811 to 1.22481, saving model to C:\\Users\\LENOVO\\Desktop\\SE\\Project\\cnn_model1.hdf5\n",
      "6/6 [==============================] - 19s 3s/step - loss: 0.0337 - accuracy: 0.9970 - val_loss: 1.2248 - val_accuracy: 0.6613\n",
      "Epoch 52/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9838\n",
      "Epoch 52: val_loss did not improve from 1.22481\n",
      "6/6 [==============================] - 18s 3s/step - loss: 0.0572 - accuracy: 0.9838 - val_loss: 1.2558 - val_accuracy: 0.6290\n",
      "Epoch 53/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9838\n",
      "Epoch 53: val_loss did not improve from 1.22481\n",
      "6/6 [==============================] - 19s 3s/step - loss: 0.0536 - accuracy: 0.9838 - val_loss: 1.3348 - val_accuracy: 0.6129\n",
      "Epoch 54/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9882\n",
      "Epoch 54: val_loss did not improve from 1.22481\n",
      "6/6 [==============================] - 19s 3s/step - loss: 0.0417 - accuracy: 0.9882 - val_loss: 1.3259 - val_accuracy: 0.6613\n",
      "Epoch 55/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9897\n",
      "Epoch 55: val_loss did not improve from 1.22481\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0353 - accuracy: 0.9897 - val_loss: 1.2729 - val_accuracy: 0.7097\n",
      "Epoch 56/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9926\n",
      "Epoch 56: val_loss did not improve from 1.22481\n",
      "6/6 [==============================] - 21s 3s/step - loss: 0.0362 - accuracy: 0.9926 - val_loss: 1.2947 - val_accuracy: 0.6452\n",
      "Epoch 57/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9926\n",
      "Epoch 57: val_loss did not improve from 1.22481\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0308 - accuracy: 0.9926 - val_loss: 1.3997 - val_accuracy: 0.6290\n",
      "Epoch 58/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9823\n",
      "Epoch 58: val_loss did not improve from 1.22481\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0515 - accuracy: 0.9823 - val_loss: 1.4273 - val_accuracy: 0.6452\n",
      "Epoch 59/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9911\n",
      "Epoch 59: val_loss did not improve from 1.22481\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0320 - accuracy: 0.9911 - val_loss: 1.4566 - val_accuracy: 0.6774\n",
      "Epoch 60/60\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9911\n",
      "Epoch 60: val_loss did not improve from 1.22481\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0370 - accuracy: 0.9911 - val_loss: 1.3992 - val_accuracy: 0.7258\n",
      "Training completed in time:  0:22:28.055802\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 60\n",
    "num_batch_size = 128\n",
    "model_file = 'cnn_model1.hdf5'\n",
    "model_path = \"C:\\\\Users\\\\LENOVO\\\\Desktop\\SE\\\\Project\\\\\"+model_file\n",
    "\n",
    "\n",
    "# Save checkpoints\n",
    "checkpointer = ModelCheckpoint(filepath=model_path, \n",
    "                               verbose=1, \n",
    "                               save_best_only=True)\n",
    "start = datetime.now()\n",
    "history = model.fit(X_train, \n",
    "                    y_train_encoded, \n",
    "                    batch_size=num_batch_size, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_split=1/12.,\n",
    "                    callbacks=[checkpointer], \n",
    "                    verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "    test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation_report(model, X_train, y_train, X_test, y_test, calc_normal=True):\n",
    "    dash = '-' * 38\n",
    "\n",
    "    # Compute scores\n",
    "    train_score, test_score = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Pint Train vs Test report\n",
    "    print('{:<10s}{:>14s}{:>14s}'.format(\"\", \"LOSS\", \"ACCURACY\"))\n",
    "    print(dash)\n",
    "    print('{:<10s}{:>14.4f}{:>14.4f}'.format( \"Training:\", train_score[0], 100 * train_score[1]))\n",
    "    print('{:<10s}{:>14.4f}{:>14.4f}'.format( \"Test:\", test_score[0], 100 * test_score[1]))\n",
    "\n",
    "\n",
    "    # Calculate and report normalized error difference?\n",
    "    if (calc_normal):\n",
    "        max_err = max(train_score[0], test_score[0])\n",
    "        error_diff = max_err - min(train_score[0], test_score[0])\n",
    "        normal_diff = error_diff * 100 / max_err\n",
    "        print('{:<10s}{:>13.2f}{:>1s}'.format(\"Normal diff \", normal_diff, \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    LOSS      ACCURACY\n",
      "--------------------------------------\n",
      "Training:         0.3914       96.3464\n",
      "Test:             1.3300       57.6087\n",
      "Normal diff         70.57 \n"
     ]
    }
   ],
   "source": [
    "# Load best saved model\n",
    "model = load_model(model_path)\n",
    "\n",
    "model_evaluation_report(model, X_train, y_train_encoded, X_test, y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error difference between Train and Test is small. To measure this different I'm using **the normalized difference between Train and Test error**, I report this as **norm diff** and show it as a percentage. If this difference is somewhere around 3.5% I will estimate the model is not overfitting. If it's negative, it will most probably be underfit.<br/>\n",
    "<br/>\n",
    "Train and test loss scores are similar and so the accuracy, with a normal diff of 3.8%, acceptable, but also just about to start overfitting as this amount of loss difference is hardly recoverable with more training.<br/>\n",
    "With **89.69%** test accuracy we are over the mean score achieved by previous works on this dataset using MFCC features and CNN networks.<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Train vs Test history plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_history(history, x_ticks_vertical=False):\n",
    "    history = history.history\n",
    "\n",
    "    # min loss / max accs\n",
    "    min_loss = min(history['loss'])\n",
    "    min_val_loss = min(history['val_loss'])\n",
    "    max_accuracy = max(history['accuracy'])\n",
    "    max_val_accuracy = max(history['val_accuracy'])\n",
    "\n",
    "    # x pos for loss / acc min/max\n",
    "    min_loss_x = history['loss'].index(min_loss)\n",
    "    min_val_loss_x = history['val_loss'].index(min_val_loss)\n",
    "    max_accuracy_x = history['accuracy'].index(max_accuracy)\n",
    "    max_val_accuracy_x = history['val_accuracy'].index(max_val_accuracy)\n",
    "\n",
    "    # summarize history for loss, display min\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.plot(history['loss'], color=\"#1f77b4\", alpha=0.7)\n",
    "    plt.plot(history['val_loss'], color=\"#ff7f0e\", linestyle=\"--\")\n",
    "    plt.plot(min_loss_x, min_loss, marker='o', markersize=3, color=\"#1f77b4\", alpha=0.7, label='Inline label')\n",
    "    plt.plot(min_val_loss_x, min_val_loss, marker='o', markersize=3, color=\"#ff7f0e\", alpha=7, label='Inline label')\n",
    "    plt.title('Model loss', fontsize=20)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(['Train', \n",
    "                'Test', \n",
    "                ('%.3f' % min_loss), \n",
    "                ('%.3f' % min_val_loss)], \n",
    "                loc='upper right', \n",
    "                fancybox=True, \n",
    "                framealpha=0.9, \n",
    "                shadow=True, \n",
    "                borderpad=1)\n",
    "\n",
    "    if (x_ticks_vertical):\n",
    "        plt.xticks(np.arange(0, len(history['loss']), 5.0), rotation='vertical')\n",
    "    else:\n",
    "        plt.xticks(np.arange(0, len(history['loss']), 5.0))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for accuracy, display max\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.plot(history['accuracy'], alpha=0.7)\n",
    "    plt.plot(history['val_accuracy'], linestyle=\"--\")\n",
    "    plt.plot(max_accuracy_x, max_accuracy, marker='o', markersize=3, color=\"#1f77b4\", alpha=7)\n",
    "    plt.plot(max_val_accuracy_x, max_val_accuracy, marker='o', markersize=3, color=\"orange\", alpha=7)\n",
    "    plt.title('Model accuracy', fontsize=20)\n",
    "    plt.ylabel('Accuracy', fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(['Train', \n",
    "                'Test', \n",
    "                ('%.2f' % max_accuracy), \n",
    "                ('%.2f' % max_val_accuracy)], \n",
    "                loc='upper left', \n",
    "                fancybox=True, \n",
    "                framealpha=0.9, \n",
    "                shadow=True, \n",
    "                borderpad=1)\n",
    "    plt.figure(num=1, figsize=(10, 6))\n",
    "\n",
    "    if (x_ticks_vertical):\n",
    "        plt.xticks(np.arange(0, len(history['accuracy']), 5.0), rotation='vertical')\n",
    "    else:\n",
    "        plt.xticks(np.arange(0, len(history['accuracy']), 5.0))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generalization gap in the plot is quite smooth, which is a good sign. We could use a larger batch size and a smoother curve -as the direction of the gradient would be more certain-, but on my test it tended much more to overfit with **256** than **128**. Lower batch size values will add some kind of regularization factor to training -because the direction of the gradient becomes less certain-.<br/>\n",
    "<br/>\n",
    "Note that test error is lower than train error: this normal as during training the error is calculated while the model is using dropout (what adds more difficulty).<br/>\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_24488\\1987032789.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_meta['pred'] = yhat_probs\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for test set\n",
    "y_probs = model.predict(X_test, verbose=0)\n",
    "\n",
    "# Get predicted labels\n",
    "yhat_probs = np.argmax(y_probs, axis=1)\n",
    "y_trues = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "# Add \"pred\" column\n",
    "test_meta['pred'] = yhat_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      amewig       0.27      0.50      0.35         6\n",
      "      amewoo       0.38      0.59      0.47        17\n",
      "      amtspa       0.50      0.42      0.45        12\n",
      "      annhum       0.67      0.73      0.70        22\n",
      "      astfly       0.83      0.71      0.77        21\n",
      "      baisan       0.50      0.36      0.42        11\n",
      "      baleag       0.44      0.67      0.53         6\n",
      "      balori       0.58      0.65      0.61        17\n",
      "      banswa       0.58      0.35      0.44        20\n",
      "      barswa       0.65      0.79      0.71        19\n",
      "\n",
      "   micro avg       0.56      0.60      0.58       151\n",
      "   macro avg       0.54      0.58      0.55       151\n",
      "weighted avg       0.59      0.60      0.58       151\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:2148: UserWarning: labels size, 10, does not match size of target_names, 12\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Build classification report\n",
    "re = classification_report(y_trues, yhat_probs, labels=[0,1,2,3,4,5,6,7,8,9], target_names=labels)\n",
    "print(re)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "84fd2673a0f847bf80637898000f9b4175f2ffd476d5f31b41a838c2acdb5b76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
